{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2220 images belonging to 8 classes.\n",
      "Found 947 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 61.1873 - accuracy: 0.1622 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 2441s 35s/step - loss: 61.1873 - accuracy: 0.1622 - val_loss: 60.0400 - val_accuracy: 0.2714 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 2424s 35s/step - loss: 60.4133 - accuracy: 0.2532 - val_loss: 59.2727 - val_accuracy: 0.4562 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 2387s 34s/step - loss: 59.8304 - accuracy: 0.3302 - val_loss: 58.9416 - val_accuracy: 0.4646 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 2393s 34s/step - loss: 59.3195 - accuracy: 0.4014 - val_loss: 58.5551 - val_accuracy: 0.5153 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 2399s 34s/step - loss: 59.0014 - accuracy: 0.4324 - val_loss: 58.4044 - val_accuracy: 0.5248 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 2398s 34s/step - loss: 58.5650 - accuracy: 0.4896 - val_loss: 58.2601 - val_accuracy: 0.5153 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 2403s 34s/step - loss: 58.2983 - accuracy: 0.5018 - val_loss: 57.6749 - val_accuracy: 0.6463 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 2413s 35s/step - loss: 57.8900 - accuracy: 0.5658 - val_loss: 57.4906 - val_accuracy: 0.6283 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 2408s 34s/step - loss: 57.6496 - accuracy: 0.5626 - val_loss: 57.3661 - val_accuracy: 0.6051 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 2398s 34s/step - loss: 57.3222 - accuracy: 0.5932 - val_loss: 56.9880 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 2401s 34s/step - loss: 57.0533 - accuracy: 0.6243 - val_loss: 56.6736 - val_accuracy: 0.6748 - lr: 9.0484e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 2396s 34s/step - loss: 56.8691 - accuracy: 0.6320 - val_loss: 56.4780 - val_accuracy: 0.6727 - lr: 8.1873e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 2382s 34s/step - loss: 56.6530 - accuracy: 0.6365 - val_loss: 56.2529 - val_accuracy: 0.7043 - lr: 7.4082e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 2401s 34s/step - loss: 56.3539 - accuracy: 0.6721 - val_loss: 56.0691 - val_accuracy: 0.7075 - lr: 6.7032e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 2409s 34s/step - loss: 56.2461 - accuracy: 0.6730 - val_loss: 55.9422 - val_accuracy: 0.6885 - lr: 6.0653e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 2397s 34s/step - loss: 56.0782 - accuracy: 0.6689 - val_loss: 55.7889 - val_accuracy: 0.6980 - lr: 5.4881e-06\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 2405s 34s/step - loss: 55.9346 - accuracy: 0.6896 - val_loss: 55.7016 - val_accuracy: 0.7096 - lr: 4.9659e-06\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 2401s 34s/step - loss: 55.7866 - accuracy: 0.6950 - val_loss: 55.5434 - val_accuracy: 0.7159 - lr: 4.4933e-06\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 2389s 34s/step - loss: 55.7100 - accuracy: 0.6896 - val_loss: 55.4748 - val_accuracy: 0.7012 - lr: 4.0657e-06\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 2391s 34s/step - loss: 55.5423 - accuracy: 0.7095 - val_loss: 55.3763 - val_accuracy: 0.7233 - lr: 3.6788e-06\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 2392s 34s/step - loss: 55.4643 - accuracy: 0.7090 - val_loss: 55.2551 - val_accuracy: 0.7360 - lr: 3.3287e-06\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 2404s 34s/step - loss: 55.3766 - accuracy: 0.7108 - val_loss: 55.1802 - val_accuracy: 0.7286 - lr: 3.0119e-06\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 2409s 34s/step - loss: 55.3316 - accuracy: 0.7086 - val_loss: 55.0520 - val_accuracy: 0.7592 - lr: 2.7253e-06\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 2396s 34s/step - loss: 55.2307 - accuracy: 0.7144 - val_loss: 55.0069 - val_accuracy: 0.7497 - lr: 2.4660e-06\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 2400s 34s/step - loss: 55.1136 - accuracy: 0.7315 - val_loss: 54.9526 - val_accuracy: 0.7540 - lr: 2.2313e-06\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 2397s 34s/step - loss: 55.0959 - accuracy: 0.7167 - val_loss: 54.8802 - val_accuracy: 0.7371 - lr: 2.0190e-06\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 2399s 34s/step - loss: 54.9922 - accuracy: 0.7437 - val_loss: 54.8294 - val_accuracy: 0.7529 - lr: 1.8268e-06\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 2396s 34s/step - loss: 54.9273 - accuracy: 0.7450 - val_loss: 54.8390 - val_accuracy: 0.7434 - lr: 1.6530e-06\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 1479s 21s/step - loss: 54.8697 - accuracy: 0.7437 - val_loss: 54.7393 - val_accuracy: 0.7540 - lr: 1.4957e-06\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 1111s 16s/step - loss: 54.8835 - accuracy: 0.7437 - val_loss: 54.7331 - val_accuracy: 0.7550 - lr: 1.3534e-06\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 1115s 16s/step - loss: 54.7743 - accuracy: 0.7423 - val_loss: 54.6274 - val_accuracy: 0.7645 - lr: 1.2246e-06\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 1115s 16s/step - loss: 54.8231 - accuracy: 0.7383 - val_loss: 54.6470 - val_accuracy: 0.7466 - lr: 1.1080e-06\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 1116s 16s/step - loss: 54.7959 - accuracy: 0.7279 - val_loss: 54.5878 - val_accuracy: 0.7751 - lr: 1.0026e-06\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.7144 - accuracy: 0.7477 - val_loss: 54.5847 - val_accuracy: 0.7603 - lr: 9.0718e-07\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.7369 - accuracy: 0.7297 - val_loss: 54.5499 - val_accuracy: 0.7687 - lr: 8.2085e-07\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 1115s 16s/step - loss: 54.6947 - accuracy: 0.7419 - val_loss: 54.5111 - val_accuracy: 0.7740 - lr: 7.4274e-07\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.6089 - accuracy: 0.7495 - val_loss: 54.4859 - val_accuracy: 0.7719 - lr: 6.7206e-07\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 1113s 16s/step - loss: 54.6498 - accuracy: 0.7473 - val_loss: 54.5085 - val_accuracy: 0.7603 - lr: 6.0810e-07\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 1116s 16s/step - loss: 54.5712 - accuracy: 0.7622 - val_loss: 54.4706 - val_accuracy: 0.7529 - lr: 5.5023e-07\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.5973 - accuracy: 0.7396 - val_loss: 54.4240 - val_accuracy: 0.7698 - lr: 4.9787e-07\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.5761 - accuracy: 0.7423 - val_loss: 54.4731 - val_accuracy: 0.7614 - lr: 4.5049e-07\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.5428 - accuracy: 0.7545 - val_loss: 54.4190 - val_accuracy: 0.7603 - lr: 4.0762e-07\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 1114s 16s/step - loss: 54.5305 - accuracy: 0.7649 - val_loss: 54.4177 - val_accuracy: 0.7603 - lr: 3.6883e-07\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 1115s 16s/step - loss: 54.5290 - accuracy: 0.7495 - val_loss: 54.3981 - val_accuracy: 0.7687 - lr: 3.3373e-07\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 1420s 20s/step - loss: 54.5486 - accuracy: 0.7491 - val_loss: 54.3911 - val_accuracy: 0.7687 - lr: 3.0197e-07\n",
      "Epoch 46/100\n",
      "53/70 [=====================>........] - ETA: 6:45 - loss: 54.5311 - accuracy: 0.7512"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Define classes\n",
    "classes = [\"Bael diseased\", \"Basil healthy\", \"Jatropa diseased\", \"Jatropa healthy\", \"Lemon diseased\", \"Lemon healthy\", \"Mango diseased\", \"Mango healthy\"]\n",
    "data_dir = r\"C:\\Users\\user7\\Desktop\\Crop Doctor\\model 3\\Dataset\"\n",
    "\n",
    "# Enhanced data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze more layers\n",
    "for layer in vgg_model.layers[:8]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_model.layers[8:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers with batch normalization and L2 regularization\n",
    "x = layers.Flatten()(vgg_model.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='fc6')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='fc7')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(len(classes), activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = models.Model(vgg_model.input, output)\n",
    "\n",
    "# Compile the model with AdamW optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch < 50:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.2)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model_vgg16.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[lr_callback, early_stopping, model_checkpoint, reduce_lr, tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "model = tf.keras.models.load_model('best_model_vgg16.h5')\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('my_model3.h5', save_format='h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(f'Predicted labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.ylabel(f'True labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted_class_name = classes[y_pred[3]]\n",
    "print(\"Predicted class name:\", predicted_class_name)\n",
    "\n",
    "classification_rep = classification_report(y_true, y_pred, target_names=classes)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17464 images belonging to 18 classes.\n",
      "Found 7477 images belonging to 18 classes.\n",
      "Epoch 1/100\n",
      "203/273 [=====================>........] - ETA: 9:56 - loss: 112.5253 - accuracy: 0.3259 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define classes\n",
    "classes = [\"Rose_Healthy_Leaf\", \"Rose_Rust\", \"Rose_sawfly_Rose_slug\", \"Soybean_healthy\", \n",
    "           \"Sugarcane_Banded_Chlorosis\", \"Sugarcane_BrownRust\", \"Sugarcane_Brown_Spot\", \n",
    "           \"Sugarcane_Grassy shoot\", \"Sugarcane_Pokkah Boeng\", \"Sugarcane_Sett Rot\", \n",
    "           \"Sugarcane_Viral Disease\", \"Sugarcane_Yellow Leaf\", \"Tea_algal_spot\", \n",
    "           \"Tea_brown_blight\", \"Tea_gray_blight\", \"Tea_healthy\", \"Tea_helopeltis\", \n",
    "           \"Tea_red_spot\"]\n",
    "data_dir = r\"C:\\Users\\user7\\Desktop\\Crop Doctor\\model 4\\Dataset\"\n",
    "\n",
    "# Enhanced data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze more layers\n",
    "for layer in vgg_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_model.layers[10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers with batch normalization and L2 regularization\n",
    "x = layers.Flatten()(vgg_model.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='fc6')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(4096, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='fc7')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(len(classes), activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = models.Model(vgg_model.input, output)\n",
    "\n",
    "# Compile the model with AdamW optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.00001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch < 50:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.2)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model_vgg16.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[lr_callback, early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "model = tf.keras.models.load_model('best_model_vgg16.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('my_model4.h5', save_format='h5')\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(f'Predicted labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.ylabel(f'True labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy_percentage:.2f}%')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted_class_name = classes[y_pred[3]]\n",
    "print(\"Predicted class name:\", predicted_class_name)\n",
    "\n",
    "classification_rep = classification_report(y_true, y_pred, target_names=classes)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
